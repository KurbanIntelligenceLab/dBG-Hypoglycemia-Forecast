{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Load and parse the Dataset (Run this first!)\n",
    "\n",
    "Update the directory which contains all xlsx files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from ParseData import parse_dataset\n",
    "from utils.PropertyNames import ColumnNames as Cols\n",
    "\n",
    "patient_data = parse_dataset(\"/home/meocakir/Documents/Datasets/Diabetes\", silent=False)\n",
    "patients = patient_data[Cols.patient].unique()\n",
    "\n",
    "len(patient_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Filter prune benchmark Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils.PropertyNames import MethodOptions as Opts\n",
    "from Benchmark import benchmark\n",
    "\n",
    "params = {\n",
    "    \"k\": 5,\n",
    "    \"risky_chars\": {0, 1},\n",
    "    \"risk_threshold\": 0.2,\n",
    "    \"prune\": True,\n",
    "    \"prune_method\": Opts.filter,\n",
    "    \"prune_threshold\": 1,\n",
    "    \"weight_thresholds\": [1, 3, 8],\n",
    "    \"value_ranges\": [(0, 2), (2, 3), (3, float('inf'))],\n",
    "    \"max_steps\": 6,\n",
    "    \"naive_threshold\": 15\n",
    "}\n",
    "\n",
    "excluded = patients.copy().tolist()\n",
    "\n",
    "#excluded.remove('P11')\n",
    "#excluded.remove('P26')\n",
    "benchmark(patient_data[patient_data[Cols.patient].isin(excluded)].copy(), start_time_range_hours=0,\n",
    "          end_time_range_hours=1, **params)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adaptive prune benchmark Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils.PropertyNames import MethodOptions as Opts\n",
    "from Benchmark import benchmark\n",
    "\n",
    "params = {\n",
    "    \"k\": 6,\n",
    "    \"risky_chars\": {0, 1},\n",
    "    \"risk_threshold\": 0.2,\n",
    "    \"prune\": True,\n",
    "    \"prune_method\": Opts.adaptive,\n",
    "    \"prune_threshold\": 1,\n",
    "    \"weight_thresholds\": [1, 4, 10],\n",
    "    \"value_ranges\": [(0, 2), (2, 3), (3, float('inf'))],\n",
    "    \"max_steps\": 6,\n",
    "    \"naive_threshold\": 15\n",
    "}\n",
    "excluded = patients.copy().tolist()\n",
    "\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "_, _, result_df = benchmark(patient_data[patient_data[Cols.patient].isin(excluded)].copy(), start_time_range_hours=0,\n",
    "          end_time_range_hours=1, **params)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adaptive prune benchmark Test on 2 patients"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot Probability Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils.VisualizationUtils import draw_histogram\n",
    "from deBruijn.ProbabilityGraph import ProbabilityGraph\n",
    "from utils.PropertyNames import MethodOptions as Opts\n",
    "from utils.PropertyNames import ColumnNames as Cols\n",
    "\n",
    "k = 4\n",
    "risky_chars: None\n",
    "params = {\n",
    "    \"prune\": False,\n",
    "    \"prune_method\": Opts.filter,\n",
    "    \"prune_threshold\": 3,\n",
    "    \"max_steps\": 3,\n",
    "}\n",
    "\n",
    "sequences = []\n",
    "for p in patients:\n",
    "    float_seq = patient_data[patient_data[Cols.patient] == p]\n",
    "    float_seq = float_seq.sort_values(Cols.date, ascending=True)[Cols.char]\n",
    "    sequences.append(float_seq)\n",
    "\n",
    "probability_graph = ProbabilityGraph(sequences=sequences, k=k)\n",
    "\n",
    "print(f\"Resulting graph: {probability_graph}\")\n",
    "\n",
    "probability_model = probability_graph.get_probability_model(**params)\n",
    "\n",
    "draw_histogram(list(probability_model.probability_dict.values()), \"Node Probability Distribution\", \"Probability\",\n",
    "               \"Count\", bins=20)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Draw timeline of one of our models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils.VisualizationUtils import draw_timeline\n",
    "from utils.PropertyNames import ColumnNames as Cols\n",
    "from utils.PropertyNames import MethodOptions as Opts\n",
    "\n",
    "from Benchmark import add_alerts, add_target_column\n",
    "\n",
    "naive_threshold = 15\n",
    "\n",
    "params = {\n",
    "    \"k\": 6,\n",
    "    \"risky_chars\": {0, 1},\n",
    "    \"risk_threshold\": 0.2,\n",
    "    \"prune\": True,\n",
    "    \"prune_method\": Opts.adaptive,\n",
    "    \"prune_threshold\": 1,\n",
    "    \"weight_thresholds\": [1, 4, 10],\n",
    "    \"value_ranges\": [(0, 2), (2, 3), (3, float('inf'))],\n",
    "    \"max_steps\": 6,\n",
    "}\n",
    "\n",
    "# Pick an alert model here\n",
    "alert_to_plot = Cols.combined_alert_and\n",
    "\n",
    "patient_data_with_alerts = add_target_column(patient_data)\n",
    "patient_data_with_alerts = add_alerts(patient_data_with_alerts, naive_threshold, **params)\n",
    "\n",
    "excluded = patients.copy().tolist()\n",
    "\n",
    "for p in [\"P1\",'P21']:\n",
    "    draw_timeline(\n",
    "        patient_data_with_alerts[patient_data_with_alerts[Cols.patient] == p].sort_values(Cols.date, ascending=True), p,\n",
    "        Cols.prob_alert, include_already_dangerous=False)\n",
    "    draw_timeline(\n",
    "        patient_data_with_alerts[patient_data_with_alerts[Cols.patient] == p].sort_values(Cols.date, ascending=True), p,\n",
    "        Cols.combined_alert_and, include_already_dangerous=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Regenerate our model with alert this time for further analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from utils.PropertyNames import ColumnNames as Cols\n",
    "from utils.PropertyNames import MethodOptions as Opts\n",
    "\n",
    "from Benchmark import add_alerts, add_target_column\n",
    "\n",
    "naive_threshold = 15\n",
    "\n",
    "params = {\n",
    "    \"k\": 6,\n",
    "    \"risky_chars\": {0, 1},\n",
    "    \"risk_threshold\": 0.2,\n",
    "    \"prune\": True,\n",
    "    \"prune_method\": Opts.adaptive,\n",
    "    \"prune_threshold\": 1,\n",
    "    \"weight_thresholds\": [1, 4, 10],\n",
    "    \"value_ranges\": [(0, 2), (2, 3), (3, float('inf'))],\n",
    "    \"max_steps\": 6,\n",
    "}\n",
    "\n",
    "patient_data_with_alerts = add_target_column(patient_data)\n",
    "patient_data_with_alerts = add_alerts(patient_data_with_alerts, naive_threshold, **params)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "See missed warnings count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "no_warning = 0\n",
    "gave_warning = 0\n",
    "\n",
    "for p in patients:\n",
    "    df = patient_data[patient_data[Cols.patient] == p].copy()\n",
    "    df = df.dropna(\n",
    "        subset=[Cols.target, Cols.naive_alert, Cols.prob_alert, Cols.combined_alert_and, Cols.combined_alert_or])\n",
    "    crossed_70 = (df[Cols.value] < 70) & (df[Cols.value].shift(1) >= 70)\n",
    "    alert_true = df[Cols.combined_alert_and].shift(1).astype(bool)\n",
    "    target_true = df[Cols.target].shift(1).astype(bool)\n",
    "\n",
    "    gave_warning += np.sum(crossed_70 & alert_true & target_true)\n",
    "    no_warning += np.sum(crossed_70 & ~alert_true & target_true)\n",
    "\n",
    "print('gave_warning:', gave_warning)\n",
    "print('no_warning:', no_warning)\n",
    "print(gave_warning / (gave_warning + no_warning))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculate forecast times"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils.VisualizationUtils import draw_histogram\n",
    "\n",
    "time_diff_list = []\n",
    "\n",
    "pdict = dict()\n",
    "\n",
    "for p in patients:\n",
    "    df = patient_data[patient_data[Cols.patient] == p].copy().sort_values(Cols.date, ascending=True).reset_index(\n",
    "        drop=True)\n",
    "    df = df.dropna(subset=[Cols.target, Cols.naive_alert, Cols.prob_alert, Cols.combined_alert_and,\n",
    "                           Cols.combined_alert_or]).reset_index(drop=True)  # Reset index after dropna\n",
    "    crossed_70 = (df[Cols.value] < 70) & (df[Cols.value].shift(1) >= 70)\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        # Check if value crosses below 70\n",
    "        if crossed_70[i]:\n",
    "            start_time = df.loc[i, Cols.date]\n",
    "            # Iterate backwards to find the earliest point where both alert and target are true\n",
    "            for j in range(i - 2, -1, -1):\n",
    "                # Ignore point if value goes under 70 again\n",
    "                if df.loc[j, Cols.value] < 70:\n",
    "                    break\n",
    "                # Check if both target and alert are true\n",
    "                elif bool(df.loc[1, Cols.combined_alert_and]) is False or bool(df.loc[1, Cols.target]):\n",
    "                    end_time = df.loc[j, Cols.date]\n",
    "                    time_diff = start_time - end_time\n",
    "                    time_diff_list.append(time_diff)\n",
    "                    if p not in pdict.keys():\n",
    "                        pdict[p] = 1\n",
    "                    else:\n",
    "                        pdict[p] += 1\n",
    "                    break  # Found the required point, no need to check further\n",
    "\n",
    "# Convert list of timedelta objects to desired format (e.g., total seconds)\n",
    "time_diff_seconds = [td.total_seconds() for td in time_diff_list]\n",
    "time_diff_minutes = [td / 60 for td in time_diff_seconds]\n",
    "time_diff_minutes = [x for x in time_diff_minutes if x <= 60]\n",
    "\n",
    "print(len(pdict), pdict)\n",
    "print(time_diff_minutes)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Draw Timeline of Forecasts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "def draw_timeline(event_times, threshold=15):\n",
    "    counter = Counter(event_times)\n",
    "\n",
    "    # Sort events\n",
    "    sorted_events = sorted(counter.items())\n",
    "\n",
    "    # Vertical spacing between events at the same time\n",
    "    vertical_step = 0.2\n",
    "\n",
    "    # Create timeline plot\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.axvline(x=0, color='red', linestyle='--', label='Hypoglycemia Event (t=0)')  # Line at t=0\n",
    "    first_x_plotted = False  # Flag to track whether the first 'x' marker has been plotted\n",
    "\n",
    "    for time, count in sorted_events:\n",
    "        mirror_time = -time  # Multiply by -1 to mirror the timeline\n",
    "        if count > threshold:\n",
    "            # If count exceeds threshold, plot a single special marker\n",
    "            plt.scatter(mirror_time, 0, marker='X', s=100, color='green')\n",
    "            plt.annotate(f'{count}\\nWarnings', (mirror_time, 0), textcoords=\"offset points\", xytext=(0,10), ha='center')  # Bold text\n",
    "        else:\n",
    "            # Calculate starting vertical offset for this time event to center it\n",
    "            vertical_offset = -(count - 1) * vertical_step / 2\n",
    "            for _ in range(count):\n",
    "                plt.scatter(mirror_time, vertical_offset, marker='x', s=50, color='blue', label='Warning Instance' if not first_x_plotted else \"\")\n",
    "                vertical_offset += vertical_step\n",
    "                first_x_plotted = True\n",
    "\n",
    "    plt.xlabel('Time (minutes)')\n",
    "    plt.title('Hypoglycemia Forecast Timeline Compilation')\n",
    "    plt.yticks([])  # Hide y-axis\n",
    "    plt.xticks(range(-35, 1, 1))  # Set x-ticks\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Test function with sample data\n",
    "draw_timeline(time_diff_minutes)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Draw ROC Curve"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import pickle\n",
    "\n",
    "filtered_df = result_df[result_df[Cols.isDangerous] == False]\n",
    "\n",
    "filtered_df = filtered_df[[Cols.combined_alert_and, Cols.target, \"Probabilistic_Alert_Prob\"]]\n",
    "\n",
    "filtered_df = filtered_df.dropna()\n",
    "\n",
    "y_true = filtered_df[Cols.target]\n",
    "y_prob = filtered_df[\"Probabilistic_Alert_Prob\"]\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(list(y_true), list(y_prob))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "data_to_save = {\n",
    "    \"roc_auc\": roc_auc,\n",
    "    \"fpr\": fpr,\n",
    "    \"tpr\": tpr\n",
    "}\n",
    "\n",
    "# Saving the data to a binary file\n",
    "with open(\"Data/roc_data.pkl\", \"wb\") as file:\n",
    "    pickle.dump(data_to_save, file)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make Stationary Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "\n",
    "from ParseData import parse_dataset\n",
    "from utils.PropertyNames import ColumnNames as Cols\n",
    "\n",
    "\n",
    "def adf_test(timeseries):\n",
    "    print(\"Results of Dickey-Fuller Test:\")\n",
    "    dftest = adfuller(timeseries, autolag=\"AIC\")\n",
    "    dfoutput = pd.Series(\n",
    "        dftest[0:4],\n",
    "        index=[\n",
    "            \"Test Statistic\",\n",
    "            \"p-value\",\n",
    "            \"#Lags Used\",\n",
    "            \"Number of Observations Used\",\n",
    "        ],\n",
    "    )\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput[\"Critical Value (%s)\" % key] = value\n",
    "    print(dfoutput)\n",
    "\n",
    "\n",
    "def kpss_test(timeseries):\n",
    "    print(\"Results of KPSS Test:\")\n",
    "    kpsstest = kpss(timeseries, regression=\"c\", nlags=\"auto\")\n",
    "    kpss_output = pd.Series(\n",
    "        kpsstest[0:3], index=[\"Test Statistic\", \"p-value\", \"Lags Used\"]\n",
    "    )\n",
    "    for key, value in kpsstest[3].items():\n",
    "        kpss_output[\"Critical Value (%s)\" % key] = value\n",
    "    print(kpss_output)\n",
    "\n",
    "\n",
    "data = parse_dataset(\"/home/meocakir/Documents/Datasets/Diabetes\", silent=False)\n",
    "patients = data[Cols.patient].unique()\n",
    "\n",
    "for patient in patients:\n",
    "    patient_data = data[data[Cols.patient] == patient]\n",
    "    patient_data = patient_data.sort_values(Cols.date, ascending=True)[Cols.value]\n",
    "    print(f'++++++++++++++++++{patient}++++++++++++++++++')\n",
    "    adf_test(patient_data)\n",
    "    kpss_test(patient_data)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
